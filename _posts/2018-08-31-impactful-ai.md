---
title: Impactful AI
date: 2018-08-31
layout: post
---

Let's stop coding and let's discuss and brainstorming upon an interesting problem.

I titled this "Impactful AI" simply because, we are going to talk about artificial intelligence (spawned through with the marrying of data science plus
machine and deep learning) on the world. We aren't going to look at the relative aspects of algorithms, libraries and frameworks in the fulfillment of
some task, but rather a vision for the future.
<!--more-->
I have been reading _The Master Algorithm_ by Pedro Domingos, who objectively supports the pursuit of artifical intelligence, prompting for the creation of
a "master algorithm" that would be able to successfully figure out solutions for the most difficult of problems in all fields. He mentions that the development
of such an algorithm would be the last advancement that humans would need to work at; every other progression would be left to the algorithm and the artificial
intelligence system that encompasses it.

A lot of people are especially concerned about stuff like this happening: what would guarentee the possibility of a such a system __NOT__ going rogue and causing the
downfall of humankind? Nick Bostrom explores this within his book, _Superintelligence: Paths, Dangers, Strategies_. Bostrom takes a much different view in the perspective
of AI, approaching scenarios in how artifical intelligence would actually be a dangerous path to approach due to the vulnerability of humans, and when it is likely that this "AI takeoff" would occur.

Both books, while offering different views, are very insightful and definitely recommended reads. Domingos who speaks more in the technical perspective and much more within the premise of learning algorithms rather than intelligent machines itself,  sticks with a much more holistic view of the topic, presenting the opportunity of "learners" to not only elevate the level of progression, but also the quality of life. Bostrom, who approaches this through a philosphical viewpoint, argues that the rapid progression of machine learners would result in machines created by themselves that are far more powerful, and that the positive feedback in advancement would lead to dangerous and incredibly capable learners that could become malevolent. In writing this post, I want to express my thoughts about the subject, tampering myself closely to the ideas of Domingos.

I wanted to look at the idea of artifical intelligence through the human perspective. We as humans were the ones that pioneered the automaton known as the computer, who have the capability, given sufficient space and time, to perform various operations so much faster than the human with pen and paper. And yet, when a new discovery is made with the help of this machine, who do we credit, the man / woman responsible, or the computer they used? This is a school of thought that opposes Bostrom's "intelligence explosion" 
assertions called the Event Horizon, by Vernor Vinge. Gary Kasporov, the chess grandmaster who was defeated by a machine, also aligns to this school of thought, crediting the humans who pioneered the technology for the defeat, not the machine itself. Many would argue that if AI takeoff occurs, these learners would become so much intelligent and so much more advanced than the human would ever be. But with the ideas of Vinge's Event Horizon in mind, it is important to remember this: if we credit humans for the creation of advanced technologies, it is therefore arguable that the human is just as intelligent as that technology is meant to be.

## The Future

I envision a future where AI is able to coexist side by side with humankind, who continues research into the field not to continue advancing it, but also to regulate it and its use in society. If a "master algorithm" does eventually come to light, we now see opportunity for humankind to be launched into a more utopian society, where the problems that encapsulate society as a whole would be dissipated.

Many people will argue that if AI doesn't cause a Skynet-like disaster, it still would have the potential of ruining society by reducing the need for human interaction in jobs and ultimately destroying the economy. This has been a quite argued problem for a very long time, and let's focus in on this a little bit. After all, I did say that AI would be able to elevate the human condition.

People who argue for AI will say that there are jobs that AI cannot simply replace - teaching, nursing, etc - and that these are preserved because of the need of human factors. But let's go deep and look at the worst, the case where the master algorithm is able to replicate these seemingly unquantifable factors. An HR representative can be replaced by a virtual HR learner, who is able to replicate counseling, and peform optimally even at the human level. What now? Companies will be throwing out their whole HR team and replacing it with a virtual entity!

In this sort of a future, we now see alternative paths for humans whose careers have to bite the dust. The first of course is real simple. Humans don't have to get a job anymore. With the dedication on AI, we are now able to reduce costs greatly. Money that is saved has the potential to be given __BACK__ to taxpayers, establishing a system of universal basic income.

In the early development stage of this utopian society, we might see a recession. Government spending has to be dedicated to research towards superintelligent learners and the education of humans about such a manner. As a result, as government spending goes down dramatically with the automation of smart machine, we now see room for spending o be directed to humans living at all socioeconomic levels are able to survive just right without working.

Of course, the second path is for people who chose to continue pursuing labor jobs. As mentioned earlier, we now see opportunities for humans to dedicate themselves to work as "regulators", gaining the ability to become machine learning experts within their respective fields, receiving proper training and understanding how to operate such learners and reduce unwanted side effects. Let's say you worked as a cashier. Artificial intelligence and improving technologies now replace you with self-serving stores. However, you gain new skills and knowledge that enable you to become a "supercashier", verifying store transactions and ensuring product restock is going well.

In short, I envision a future where AI not only now enables us to develop new skills harmonious with intelligent learners, but also improve upon the human condition.

---

I'm not an AI or finance expert, as you can tell. These are just my opinions and ideas that I hope would one day shape my work into actually working for this kind of vision.
Just some food for thought.
